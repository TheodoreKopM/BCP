{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0008ace-9cdc-471b-a288-c3d5d24b6efd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Vector Search Configuration\n",
    "VECTOR_SEARCH_ENDPOINT = \"bcp_confluence_store\"\n",
    "VECTOR_SEARCH_INDEX = \"theodore_kop_personal.bcp.bcp_chunked_docs_managed_index\"\n",
    "\n",
    "# Unity Catalog Configuration\n",
    "UC_CATALOG = \"theodore_kop_personal\"\n",
    "UC_SCHEMA = \"bcp\"\n",
    "RAG_APP_NAME = \"bcp_confluence_documents_rag_poc\"\n",
    "\n",
    "# Data Pipeline Configuration\n",
    "data_pipeline_config = {\n",
    "    # Vector Search index configuration\n",
    "    \"vectorsearch_config\": {\n",
    "        \"pipeline_type\": \"CONTINUOUS\",\n",
    "    },\n",
    "    # Embedding model to use\n",
    "    \"embedding_config\": {\n",
    "        \"embedding_endpoint_name\": \"databricks-bge-large-en\",\n",
    "        \"embedding_tokenizer\": {\n",
    "            \"tokenizer_model_name\": \"BAAI/bge-large-en-v1.5\",\n",
    "            \"tokenizer_source\": \"hugging_face\",\n",
    "        },\n",
    "    },\n",
    "    # Parsing and chunking configuration\n",
    "    \"pipeline_config\": {\n",
    "        \"file_format\": \"pdf\",\n",
    "        \"parser\": {\"name\": \"pypdf\", \"config\": {}},\n",
    "        \"chunker\": {\n",
    "            \"name\": \"langchain_recursive_char\",\n",
    "            \"config\": {\n",
    "                \"chunk_size_tokens\": 1024,\n",
    "                \"chunk_overlap_tokens\": 512,\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Destination Tables Configuration\n",
    "destination_tables_config = {\n",
    "    \"raw_files_table_name\": f\"`{UC_CATALOG}`.`{UC_SCHEMA}`.`raw_files`\",\n",
    "    \"parsed_docs_table_name\": f\"`{UC_CATALOG}`.`{UC_SCHEMA}`.`parsed_docs`\",\n",
    "    \"chunked_docs_table_name\": f\"`{UC_CATALOG}`.`{UC_SCHEMA}`.`chunked_docs`\",\n",
    "    \"vectorsearch_index_table_name\": f\"`{UC_CATALOG}`.`{UC_SCHEMA}`.`bcp_chunked_docs_managed_index`\",\n",
    "}\n",
    "destination_tables_config[\"vectorsearch_index_name\"] = destination_tables_config[\"vectorsearch_index_table_name\"].replace(\"`\", \"\")\n",
    "\n",
    "# Chain configuration\n",
    "rag_chain_config = {\n",
    "    \"databricks_resources\": {\n",
    "        \"vector_search_endpoint_name\": VECTOR_SEARCH_ENDPOINT,\n",
    "        \"llm_endpoint_name\": \"databricks-claude-3-7-sonnet\",\n",
    "    },\n",
    "    \"retriever_config\": {\n",
    "        \"vector_search_index\": VECTOR_SEARCH_INDEX,\n",
    "        \"schema\": {\n",
    "            # The column name in the retriever's response referred to the unique key\n",
    "            # If using Databricks vector search with delta sync, this should the column of the delta table that acts as the primary key\n",
    "            \"primary_key\": \"chunk_id\",\n",
    "            # The column name in the retriever's response that contains the returned chunk.\n",
    "            \"chunk_text\": \"chunked_text\",\n",
    "            # The template of the chunk returned by the retriever - used to format the chunk for presentation to the LLM.\n",
    "            \"document_uri\": \"path\",\n",
    "        },\n",
    "        # Prompt template used to format the retrieved information to present to the LLM to help in answering the user's question\n",
    "        \"chunk_template\": \"Passage: {chunk_text}\\nSource: {document_uri}\\n\",\n",
    "        # The column name in the retriever's response that refers to the original document.\n",
    "        \"parameters\": {\n",
    "            # Number of search results that the retriever returns\n",
    "            \"k\": 8,\n",
    "            # Type of search to run\n",
    "            # Semantic search: `ann`\n",
    "            # Hybrid search (keyword + sementic search): `hybrid`\n",
    "            \"query_type\": \"hybrid\",\n",
    "        },\n",
    "        # Tag for the data pipeline, allowing you to easily compare the POC results vs. future data pipeline configurations you try.\n",
    "        \"data_pipeline_tag\": \"bcp_doc_poc\",\n",
    "    },\n",
    "    \"llm_config\": {\n",
    "        # Define a template for the LLM prompt.  This is how the RAG chain combines the user's question and the retrieved context.\n",
    "        \"llm_system_prompt_template\": \"\"\"You are an insightful and helpful assistant for BCP that only answers questions related to BCP internal documentation. Use the following pieces of retrieved context to answer the question. Some pieces of context may be irrelevant, in which case you should not use them to form the answer. Answer honestly and if you do not now the answer or if the answer is not contained in the documentation provided as context, limit yourself to answer that \"You could not find the answer in the documentation and prompt the user to provide more details\"\n",
    "\n",
    "        Context: {context}\"\"\".strip(),\n",
    "        \"llm_parameters\": {\"temperature\": 0, \"max_tokens\": 2000},\n",
    "    },\n",
    "    \"input_example\": {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Qu√© es un EDV?\",\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "\n",
    "def create_rag_chain_config():\n",
    "    \"\"\"Create the rag_chain_config.yaml file with the specified configuration.\"\"\"\n",
    "    # Create the yaml file\n",
    "    with open(\"rag_chain_config.yaml\", \"w\") as f:\n",
    "        yaml.dump(rag_chain_config, f, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    print(\"Created rag_chain_config.yaml successfully!\")\n",
    "\n",
    "def create_data_pipeline_config():\n",
    "    \"\"\"Create the data_pipeline_config.yaml file.\"\"\"\n",
    "    with open(\"data_pipeline_config.yaml\", \"w\") as f:\n",
    "        yaml.dump(data_pipeline_config, f, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    print(\"Created data_pipeline_config.yaml successfully!\")\n",
    "\n",
    "def create_destination_tables_config():\n",
    "    \"\"\"Create the destination_tables_config.yaml file.\"\"\"\n",
    "    with open(\"destination_tables_config.yaml\", \"w\") as f:\n",
    "        yaml.dump(destination_tables_config, f, default_flow_style=False, sort_keys=False)\n",
    "    \n",
    "    print(\"Created destination_tables_config.yaml successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    create_rag_chain_config()\n",
    "    create_data_pipeline_config()\n",
    "    create_destination_tables_config() "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "global_config.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
